{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hw1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import os \n",
    "%matplotlib inline\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "# import keras\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Convolution2D, MaxPool2D, BatchNormalization, SeparableConv2D, Activation\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, ModelCheckpoint\n",
    "from keras.layers import Input\n",
    "from tensorflow.python.keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n",
    "sns.set(style='white', context='notebook', palette='deep')\n",
    "\n",
    "# import PIL\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "# import scipy\n",
    "from scipy.signal import convolve2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = 13\n",
    "input_size = 256\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the Pretrain Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Model)                (None, 8, 8, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               8388864   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 13)                3341      \n",
      "=================================================================\n",
      "Total params: 28,417,613\n",
      "Trainable params: 8,392,717\n",
      "Non-trainable params: 20,024,896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier = load_model('pretrain_model.h5')\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### show Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "input_1                        False\n",
      "----------------------------------------\n",
      "block1_conv1                   False\n",
      "----------------------------------------\n",
      "block1_conv2                   False\n",
      "----------------------------------------\n",
      "block1_pool                    False\n",
      "----------------------------------------\n",
      "block2_conv1                   False\n",
      "----------------------------------------\n",
      "block2_conv2                   False\n",
      "----------------------------------------\n",
      "block2_pool                    False\n",
      "----------------------------------------\n",
      "block3_conv1                   False\n",
      "----------------------------------------\n",
      "block3_conv2                   False\n",
      "----------------------------------------\n",
      "block3_conv3                   False\n",
      "----------------------------------------\n",
      "block3_conv4                   False\n",
      "----------------------------------------\n",
      "block3_pool                    False\n",
      "----------------------------------------\n",
      "block4_conv1                   False\n",
      "----------------------------------------\n",
      "block4_conv2                   False\n",
      "----------------------------------------\n",
      "block4_conv3                   False\n",
      "----------------------------------------\n",
      "block4_conv4                   False\n",
      "----------------------------------------\n",
      "block4_pool                    False\n",
      "----------------------------------------\n",
      "block5_conv1                   False\n",
      "----------------------------------------\n",
      "block5_conv2                   False\n",
      "----------------------------------------\n",
      "block5_conv3                   False\n",
      "----------------------------------------\n",
      "block5_conv4                   False\n",
      "----------------------------------------\n",
      "block5_pool                    False\n",
      "----------------------------------------\n",
      "flatten_1                       True\n",
      "----------------------------------------\n",
      "dense_1                         True\n",
      "----------------------------------------\n",
      "batch_normalization_1           True\n",
      "----------------------------------------\n",
      "activation_1                    True\n",
      "----------------------------------------\n",
      "dropout_1                       True\n",
      "----------------------------------------\n",
      "dense_2                         True\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(classifier.layers):\n",
    "    if i == 0:\n",
    "        for layer0 in classifier.layers[i].layers[:]:\n",
    "            layer0.trainable = False\n",
    "            print('-'*40)\n",
    "            print('%-25s'%layer0.name, '%10s'%layer0.trainable)\n",
    "    else:\n",
    "        print('-'*40)\n",
    "        print('%-25s'%layer.name, '%10s'%layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_size(full_data=False, validation_split_ratio=0.2):\n",
    "    if full_data:\n",
    "        valid_split = 0.05\n",
    "    else:\n",
    "        valid_split = validation_split_ratio\n",
    "        \n",
    "    train_datagen = ImageDataGenerator(\n",
    "        height_shift_range=0.2,\n",
    "        width_shift_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        validation_split=valid_split)\n",
    "\n",
    "    valid_datagen = ImageDataGenerator(\n",
    "        validation_split=valid_split)\n",
    "    \n",
    "    return train_datagen, valid_datagen\n",
    "train_datagen, valid_datagen = training_size(full_data=True, validation_split_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2684 images belonging to 13 classes.\n",
      "Found 135 images belonging to 13 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(\n",
    "    'cs-ioc5008-hw1/train',\n",
    "    target_size=(256, 256),\n",
    "    subset='training',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    seed=3023)\n",
    "\n",
    "validation_set = valid_datagen.flow_from_directory(\n",
    "    'cs-ioc5008-hw1/train',\n",
    "    target_size=(256, 256),\n",
    "    subset='validation',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    seed=3023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bedroom': 0,\n",
       " 'coast': 1,\n",
       " 'forest': 2,\n",
       " 'highway': 3,\n",
       " 'insidecity': 4,\n",
       " 'kitchen': 5,\n",
       " 'livingroom': 6,\n",
       " 'mountain': 7,\n",
       " 'office': 8,\n",
       " 'opencountry': 9,\n",
       " 'street': 10,\n",
       " 'suburb': 11,\n",
       " 'tallbuilding': 12}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict = training_set.class_indices\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=0.0001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "optimizer = SGD(lr=0.0001, momentum=0.9)\n",
    "\n",
    "classifier.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save model when meets the highest validation set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = ModelCheckpoint('model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "45/45 [==============================] - 72s 2s/step - loss: 2.0364 - accuracy: 0.6100 - val_loss: 0.0116 - val_accuracy: 0.8296\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.82963, saving model to pretrain_bs64_spe45.h5\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 59s 1s/step - loss: 0.3958 - accuracy: 0.8625 - val_loss: 0.0065 - val_accuracy: 0.8889\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.82963 to 0.88889, saving model to pretrain_bs64_spe45.h5\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 58s 1s/step - loss: 0.2865 - accuracy: 0.9148 - val_loss: 0.0046 - val_accuracy: 0.9630\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.88889 to 0.96296, saving model to pretrain_bs64_spe45.h5\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 57s 1s/step - loss: 0.2317 - accuracy: 0.9265 - val_loss: 0.0065 - val_accuracy: 0.9556\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.96296\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 59s 1s/step - loss: 0.1937 - accuracy: 0.9378 - val_loss: 0.0067 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.96296\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 57s 1s/step - loss: 0.1670 - accuracy: 0.9429 - val_loss: 0.0046 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.96296\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 58s 1s/step - loss: 0.1404 - accuracy: 0.9604 - val_loss: 0.0037 - val_accuracy: 0.9407\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.96296\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 58s 1s/step - loss: 0.1397 - accuracy: 0.9568 - val_loss: 0.0029 - val_accuracy: 0.9481\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.96296\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 59s 1s/step - loss: 0.1205 - accuracy: 0.9635 - val_loss: 0.0064 - val_accuracy: 0.9556\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.96296\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 58s 1s/step - loss: 0.1218 - accuracy: 0.9652 - val_loss: 0.0083 - val_accuracy: 0.9481\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.96296\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 58s 1s/step - loss: 0.1108 - accuracy: 0.9656 - val_loss: 0.0067 - val_accuracy: 0.9481\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.96296\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 59s 1s/step - loss: 0.0952 - accuracy: 0.9725 - val_loss: 0.0058 - val_accuracy: 0.9407\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.96296\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 61s 1s/step - loss: 0.0862 - accuracy: 0.9725 - val_loss: 0.0042 - val_accuracy: 0.9556\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.96296\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 60s 1s/step - loss: 0.0918 - accuracy: 0.9691 - val_loss: 0.0012 - val_accuracy: 0.9407\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.96296\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 58s 1s/step - loss: 0.0782 - accuracy: 0.9757 - val_loss: 0.0017 - val_accuracy: 0.9407\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.96296\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 59s 1s/step - loss: 0.0653 - accuracy: 0.9805 - val_loss: 0.0014 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.96296\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 59s 1s/step - loss: 0.0697 - accuracy: 0.9812 - val_loss: 6.4577e-04 - val_accuracy: 0.9556\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.96296\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 60s 1s/step - loss: 0.0753 - accuracy: 0.9777 - val_loss: 0.0022 - val_accuracy: 0.9407\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.96296\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 60s 1s/step - loss: 0.0761 - accuracy: 0.9774 - val_loss: 0.0036 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.96296\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 60s 1s/step - loss: 0.0616 - accuracy: 0.9806 - val_loss: 7.7571e-04 - val_accuracy: 0.9481\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.96296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f3dea860b38>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(\n",
    "    training_set,\n",
    "    steps_per_epoch=45,\n",
    "    epochs=20,\n",
    "    validation_data=validation_set,\n",
    "    validation_steps=32.5,\n",
    "    verbose=1,\n",
    "    callbacks = [ac]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the previously stored model to predict the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'cs-ioc5008-hw1/test/'\n",
    "file = sorted(glob.glob(file_path + '*.jpg'))\n",
    "y_pred = []\n",
    "\n",
    "for i in range(len(file)):\n",
    "    images = image.load_img(file[i], target_size=(256, 256, 3))\n",
    "    x = image.img_to_array(images)\n",
    "    x = x.reshape([-1, 256, 256, 3])\n",
    "    x = model.predict(x)\n",
    "    x = np.argmax(x, axis = 1)\n",
    "    y_pred.append(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'bedroom',\n",
       " 1: 'coast',\n",
       " 2: 'forest',\n",
       " 3: 'highway',\n",
       " 4: 'insidecity',\n",
       " 5: 'kitchen',\n",
       " 6: 'livingroom',\n",
       " 7: 'mountain',\n",
       " 8: 'office',\n",
       " 9: 'opencountry',\n",
       " 10: 'street',\n",
       " 11: 'suburb',\n",
       " 12: 'tallbuilding'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.listdir('cs-ioc5008-hw1/train/')\n",
    "labels = sorted([p for p in path])\n",
    "labels = dict(zip([i for i in range(len(labels))], labels))\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>image_0000</td>\n",
       "      <td>highway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>image_0001</td>\n",
       "      <td>bedroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>image_0002</td>\n",
       "      <td>suburb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>image_0003</td>\n",
       "      <td>bedroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>image_0004</td>\n",
       "      <td>tallbuilding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1035</td>\n",
       "      <td>image_1035</td>\n",
       "      <td>mountain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1036</td>\n",
       "      <td>image_1036</td>\n",
       "      <td>opencountry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1037</td>\n",
       "      <td>image_1037</td>\n",
       "      <td>coast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1038</td>\n",
       "      <td>image_1038</td>\n",
       "      <td>forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1039</td>\n",
       "      <td>image_1039</td>\n",
       "      <td>tallbuilding</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1040 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id         label\n",
       "0     image_0000       highway\n",
       "1     image_0001       bedroom\n",
       "2     image_0002        suburb\n",
       "3     image_0003       bedroom\n",
       "4     image_0004  tallbuilding\n",
       "...          ...           ...\n",
       "1035  image_1035      mountain\n",
       "1036  image_1036   opencountry\n",
       "1037  image_1037         coast\n",
       "1038  image_1038        forest\n",
       "1039  image_1039  tallbuilding\n",
       "\n",
       "[1040 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_tolabel = [labels[i] for i in y_pred]\n",
    "submission = pd.read_csv('cs-ioc5008-hw1/sameple_submission.csv')\n",
    "submission['label'] = y_pred_tolabel\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### output the prediction set and submit to kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
